{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running the spot detection notebook, run the first notebook, \"Read_files_create_batch.ipynb'.\n",
    "\n",
    "In this notebook we will detect the fish spots using an automatic method called UFISH and a semi manual one\n",
    "called BIGFISH.\n",
    "\n",
    "23/05/25     Jacques Bourg @ Florian Muller lab. Institut Pasteur.\n",
    "\n",
    "<img src=\"./HOX_pipeline.png\" alt=\"LNP pipeline\" width=\"1200\" height=\"477\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import skimage.io as io\n",
    "import napari\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "base_dir = Path(\"../../src\").resolve()\n",
    "sys.path.append(str(base_dir))\n",
    "sys.path.append(str(base_dir / \"utils\"))\n",
    "sys.path.append(str(base_dir / \"detection_fish\"))\n",
    "sys.path.append(str(base_dir / \"segmentation\"))\n",
    "\n",
    "from utils.parameters_tracking import Parameter_tracking as Track\n",
    "from utils.file_handling import FileProcessor\n",
    "from detection_fish.detect_fish_spots import DetectionPipeline\n",
    "from detection_fish.thresh_big_fish_napariV3 import SpotsThresholding \n",
    "from segmentation.refine_seg import Segmentation\n",
    "\n",
    "tk  = Track()\n",
    "det = DetectionPipeline()\n",
    "sg  = Segmentation()\n",
    "fp  = FileProcessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = str(Path('../Analysis'))\n",
    "batch_folders = os.listdir(var)\n",
    "dropdown = widgets.Dropdown(options=batch_folders, description='Select:', layout=widgets.Layout(width='auto', min_width='150px'))\n",
    "display(dropdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n         = np.where(np.array(batch_folders) == dropdown.value)[0][0]\n",
    "file_path = str(Path(var) / Path(batch_folders[n]) / Path(batch_folders[n] +'.json'))\n",
    "constants = tk.load_json(file_path)\n",
    "batch_name= constants['BATCH_NAME']; print(batch_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modalities = constants['MODALITIES']\n",
    "dropdown2 = widgets.Dropdown(options=modalities, description='Select:', layout=widgets.Layout(width='auto', min_width='150px'))\n",
    "display(dropdown2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n2       = np.where(np.array(modalities) == dropdown2.value)[0][0]\n",
    "modality = modalities[n2]; print(modality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_cell = constants['CHANNELS'] # (Doesn't make sense to select DAPI)\n",
    "dropdown3    = widgets.Dropdown(options=channel_cell, description='Select:', layout=widgets.Layout(width='auto', min_width='150px')); display(dropdown3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n3     = np.where(np.array(channel_cell) == dropdown3.value)[0][0]\n",
    "chan_c = channel_cell[n3]; print(chan_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_fish = constants[f'BATCH_{modality}_{chan_c}']; print(batch_fish);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spots_folder = Path(f'../Analysis/{batch_name}/{modality}/{chan_c}/spots')\n",
    "if not spots_folder.exists():\n",
    "    spots_folder.mkdir(parents=True)\n",
    "print(spots_folder)\n",
    "\n",
    "spots_ufish_folder = Path(f'../Analysis/{batch_name}/{modality}/{chan_c}/spots/UFISH')\n",
    "if not spots_ufish_folder.exists():\n",
    "    spots_ufish_folder.mkdir(parents=True)\n",
    "print(spots_ufish_folder)\n",
    "\n",
    "spots_bigfish_folder = Path(f'../Analysis/{batch_name}/{modality}/{chan_c}/spots/BIGFISH')\n",
    "if not spots_bigfish_folder.exists():\n",
    "    spots_bigfish_folder.mkdir(parents=True)\n",
    "print(spots_bigfish_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a) UFISH (without deconvolution)\n",
    "\n",
    "base_dir        = str(Path().resolve().parent.parent)\n",
    "dots_ufish_path = spots_ufish_folder / f\"dots_{modality}_{chan_c}_UFISH.npy\"\n",
    "viewer4         = napari.Viewer(title=\"UFISH on raw data\")\n",
    "dict_ufish_dots = {}\n",
    "dict_ufish_dots_local_copy = {}  # this dict contains the same information but the keys are different\n",
    "\n",
    "counter = 0\n",
    "for ind_l, file in enumerate(batch_fish):\n",
    "    file            = Path(file)\n",
    "    file_abs_path   = str(Path(batch_fish[ind_l]).resolve())\n",
    "    im_rna          = io.imread(batch_fish[ind_l])\n",
    "    target_dir      = str(Path().resolve().parent / Path(f'Analysis/{batch_name}/detected_ufish.npy'))\n",
    "    spots_uf_raw    = det.spot_ufish(file_abs_path, target_dir, base_dir)\n",
    "    \n",
    "    if im_rna.ndim == 3:\n",
    "        mip_im_rna = np.max(im_rna, axis=0)    \n",
    "    elif im_rna.ndim == 2:\n",
    "        mip_im_rna = im_rna\n",
    "    \n",
    "    if np.shape(spots_uf_raw)[1] == 3:\n",
    "        spots_uf_raw_2d = spots_uf_raw[:,1:]\n",
    "    elif np.shape(spots_uf_raw)[1] == 2:    \n",
    "        spots_uf_raw_2d = spots_uf_raw\n",
    "    \n",
    "    val = np.percentile(mip_im_rna, 99)    \n",
    "    viewer4.add_image(mip_im_rna, contrast_limits=(0, val), rgb=False, name=f\"{modality} {file.stem}\", opacity=0.8)\n",
    "    viewer4.add_points(spots_uf_raw_2d, name=f\"Spots {modality} {file.stem}\", size=4,  border_color='#FF0000', face_color=[0, 0, 0, 0]);\n",
    "\n",
    "    if counter != 0:\n",
    "        viewer4.layers[f\"{modality} {file.stem}\"].visible       = False\n",
    "        viewer4.layers[f\"Spots {modality} {file.stem}\"].visible = False \n",
    "\n",
    "    base_name = '_'.join(file.stem.split('_')[:-1])\n",
    "    dict_ufish_dots[base_name] = spots_uf_raw\n",
    "    dict_ufish_dots_local_copy[file.stem] = spots_uf_raw\n",
    "    counter += 1\n",
    "\n",
    "format_spots = 'spots_IDzyx'\n",
    "fp.save_spots_distributed_files(dots_ufish_path, format_spots, dict_ufish_dots, im_rna.ndim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adjust the threshold by eye. Often there is some kind of inflexion point in the counts vs threshold curve at which the noise distribution and the signal distribution overlap.\n",
    "When one doesn't see this point look for a point in the noisy regime (left) which the derivative decreases in absolute value.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "format_spots        = 'spots_IDzyx'\n",
    "dot_ufish_path      = spots_ufish_folder / f\"dots_{modality}_{chan_c}_UFISH.npy\"\n",
    "dict_ufish_dots     = fp.load_spots_distributed_files(dot_ufish_path, format=format_spots)\n",
    "\n",
    "voxel_size_nm       = (108, 108)   # (z,y,x) or (y,x)  this parameter is important, you can check it's value opening the original files in fiji (Image/show info), or in the microscope metadata\n",
    "object_radius_nm    = (432, 432)   # estimate this parameter by eye: number of pixels of spots diameter times the voxels size (respective Z, Y and X dimension)\n",
    "\n",
    "batch_path          = [Path(el) for el in batch_fish]\n",
    "dots_bigfish_path   = spots_bigfish_folder / f\"dots_{modality}_{chan_c}_BIGFISH.npy\"\n",
    "thresh_bigfish_path = spots_bigfish_folder / f\"thresh_{modality}_{chan_c}_BIGFISH.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sth0 = SpotsThresholding(BATCH = batch_path, BATCH_NAME= batch_name, voxel_size_nm=voxel_size_nm, \n",
    "                         object_radius_nm=object_radius_nm, spots_other_method=dict_ufish_dots_local_copy, subtract_fish=False)\n",
    "sth0.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After closing the app, pursue here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename the keys in order to have as key only the base name\n",
    "dict_dots = {}\n",
    "for key, value in sth0.detected_spots.items():\n",
    "    dict_dots['_'.join(key.split('_')[:-1])] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp.save_spots_distributed_files(dots_bigfish_path, format_spots, dict_dots, im_rna.ndim)\n",
    "np.save(thresh_bigfish_path, sth0.dict_thresh_spot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exec(f\"DOTS_UFISH_{modality}_{chan_c}_PATH   = dots_ufish_path\", globals())\n",
    "exec(f\"DOTS_BIGFISH_{modality}_{chan_c}_PATH = dots_bigfish_path\", globals())\n",
    "exec(f\"THRESH_BIGFISH_{modality}_{chan_c}_PATH = thresh_bigfish_path\", globals())\n",
    "exec(f\"SPOTS_FOLDER_{modality}_{chan_c}_PATH = spots_folder\")\n",
    "exec(f\"SPOTS_FORMAT = format_spots\")\n",
    "\n",
    "exec(f\"VOXEL_SIZE_NM_BF_{modality}_{chan_c}_Z = voxel_size_nm[0]\", globals())\n",
    "exec(f\"VOXEL_SIZE_NM_BF_{modality}_{chan_c}_YX = voxel_size_nm[1]\", globals())\n",
    "exec(f\"OBJECT_RADIUS_NM_BF{modality}_{chan_c}_Z = object_radius_nm[0]\", globals())\n",
    "exec(f\"OBJECT_RADIUS_NM_BF{modality}_{chan_c}_YX = object_radius_nm[1]\", globals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "constants2 = tk.collect_constants()\n",
    "tk.save_constants_and_commit_hash(constants2, batch_name, folder_path = Path(f\"../Analysis/{batch_name}\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base_env_apifish",
   "language": "python",
   "name": "base_env_apifish"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
