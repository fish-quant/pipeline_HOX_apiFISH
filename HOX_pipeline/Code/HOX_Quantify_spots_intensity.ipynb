{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the first notebook for quantification of FISH expression. In here we quantify intensity in \n",
    "various forms (histograms of spot intensities, spot sizes and summed spot intensities).\n",
    "We also quantify the SNR, the signal to noise ratio and the background.\n",
    "\n",
    "\n",
    "23/04/25     Jacques Bourg @ Florian Muller lab. Institut Pasteur.\n",
    "\n",
    "<img src=\"./HOX_pipeline.png\" alt=\"LNP pipeline\" width=\"1200\" height=\"477\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.io as io\n",
    "import napari\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "base_dir = Path(\"../../src\").resolve()\n",
    "sys.path.append(str(base_dir))\n",
    "sys.path.append(str(base_dir / \"utils\"))\n",
    "sys.path.append(str(base_dir / \"detection_fish\"))\n",
    "sys.path.append(str(base_dir / \"segmentation\"))\n",
    "sys.path.append(str(base_dir / \"synthesis\"))\n",
    "\n",
    "from utils.parameters_tracking import Parameter_tracking as Track\n",
    "from utils.plots import Plots\n",
    "from utils.file_handling import FileProcessor\n",
    "from segmentation.refine_seg import Segmentation\n",
    "from synthesis.synthesize import Synthesis\n",
    "\n",
    "tk  = Track()\n",
    "sg  = Segmentation()\n",
    "pt  = Plots()\n",
    "st  = Synthesis()\n",
    "fp  = FileProcessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = str(Path('../Analysis'))\n",
    "batch_folders = os.listdir(var)\n",
    "dropdown = widgets.Dropdown(options=batch_folders, description='Select:', layout=widgets.Layout(width='auto', min_width='150px'))\n",
    "display(dropdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n         = np.where(np.array(batch_folders) == dropdown.value)[0][0]\n",
    "file_path = str(Path(var) / Path(batch_folders[n]) / Path(batch_folders[n] +'.json'))\n",
    "constants = tk.load_json(file_path)\n",
    "batch_name= constants['BATCH_NAME']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modalities = constants['MODALITIES']\n",
    "dropdown2 = widgets.Dropdown(options=modalities, description='Select:', layout=widgets.Layout(width='auto', min_width='150px'))\n",
    "display(dropdown2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n2  = np.where(np.array(modalities) == dropdown2.value)[0][0]\n",
    "modality = modalities[n2]; print(modality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels_cell = constants['CHANNELS'] # DAPI doesn't make sense\n",
    "dropdown3 = widgets.Dropdown(options=channels_cell, description='Select:', layout=widgets.Layout(width='auto', min_width='150px'));\n",
    "display(dropdown3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n3     = np.where(np.array(channels_cell) == dropdown3.value)[0][0]\n",
    "chan_c = channels_cell[n3]; print(chan_c)\n",
    "\n",
    "col_channels = constants['COLORS']  # associated color to this channel\n",
    "color        = col_channels[n3]; print(color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_methods = ['UFISH','BIGFISH']\n",
    "dropdown4         = widgets.Dropdown(options=detection_methods, description='Select:', layout=widgets.Layout(width='auto', min_width='150px'))\n",
    "display(dropdown4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n4     = np.where(np.array(detection_methods) == dropdown4.value)[0][0]\n",
    "method = detection_methods[n4]; print(method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path_figures = Path(f\"../Analysis/{batch_name}/Figures\") # create folder for figures (all figures will be stored there)\n",
    "if not folder_path_figures.exists():\n",
    "    folder_path_figures.mkdir(parents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spot intensity: extract intensity, spot size, summed spot intensity over estimated size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_fish         = constants[f'BATCH_{modality}_{chan_c}']\n",
    "\n",
    "dots_path          = constants[f'DOTS_{method}_{modality}_{chan_c}_PATH']\n",
    "dict_dots          = fp.load_spots_distributed_files(dots_path, constants['SPOTS_FORMAT'])\n",
    "\n",
    "window_size        = 17#13, 7      # This parameter is critical\n",
    "n_int_points       = 11\n",
    "median_filt_size   = 4\n",
    "frac               = .15#0.25   # This parameter is critical. \n",
    "#   Anyhow validate visually afterwards with the napari window. Iterate until the dot size estimation makes sense visually.\n",
    "\n",
    "voxel_size_yx      = constants[f'VOXEL_SIZE_NM_BF_{modality}_{chan_c}_YX']\n",
    "obj_rad_yx         = constants[f'OBJECT_RADIUS_NM_BF{modality}_{chan_c}_YX']\n",
    "\n",
    "voxel_size_nm      = (voxel_size_yx, voxel_size_yx)  # important parameter: might be seen opening the image information in fiji or loooking at the microscope metadata.\n",
    "object_radius_nm   = (obj_rad_yx, obj_rad_yx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batch processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind_l, file in enumerate(batch_fish):\n",
    "    im_rna                   = io.imread(Path(file))   \n",
    "    file_name                = Path(file).stem     \n",
    "    filebase_name            = '_'.join(file_name.split('_')[:-1])\n",
    "\n",
    "    df_spots_filt            = dict_dots[filebase_name]\n",
    "    df_w_intensity           = sg.extract_intensities_df(df_spots_filt, im_rna)  \n",
    "    df_w_frac_signal         = sg.determine_spots_width_frac_signal_df(im_rna, df_w_intensity, h_window=window_size, size_median_filt=median_filt_size, frac=frac)\n",
    "    df_w_sum_intensity       = sg.compute_sum_spot_intensity_df(df_w_frac_signal, im_rna)\n",
    "    df_w_snr_back            = st.compute_snr_df(im_rna, df_w_sum_intensity, voxel_size_nm, object_radius_nm)        \n",
    "    dict_dots[filebase_name] = df_w_snr_back\n",
    "                    \n",
    "fp.save_spots_distributed_files(dots_path, constants['SPOTS_FORMAT'], dict_dots, im_rna.ndim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Manual step      (WARNING: Manual input required)\n",
    "Organize your batch in rows and columns: rows can be conditions, and columns time or rows can be repetitions and columns conditions\n",
    "store as (line, column) for each element of the batch. Put None in case you don't want to display it. \n",
    "For instance if your batch files is ['file_control0', 'file_control1', 'file_control2', 'file_rep1_c1', 'file_rep2_c1', 'file_rep1_c2', 'file_rep2_c2'] and you want to organize your \n",
    "display as:\n",
    "\n",
    "|          | Concentration 1 | Concentration 2 |\n",
    "|----------|----------|----------|\n",
    "| **Rep 1**| R1, C1   | R1, C2   | \n",
    "| **Rep 2**| R2, C1   | R2, C2   |\n",
    "\n",
    "\n",
    "Then, insert the coordinates, in the following way,  do for a batch of experiments like:\n",
    "\n",
    "batch      = [`Exp to discard`, `Exp to discard`, `Exp to discard`, `R1,C1`, `R2,C1`,`R1,C2`,  `R2,C2` ]\n",
    "\n",
    "batch_plot = [`None` &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;,  `None`&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;,  `None `&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;,`(0,0) `,`(1,0) `,`(0,1) `,`(1,1)`]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leg_x = ['6h', '24h', '48h']\n",
    "leg_y = ['NT', 'GDF', 'FGF-GDF']\n",
    "name  = f'{modality}_{chan_c}_{method}'\n",
    "\n",
    "lines = len(leg_y)\n",
    "cols  = len(leg_x)\n",
    "\n",
    "print([Path(el).stem for el in batch_fish])\n",
    "batch_plot         = [(0,0), (0,1), (0,2), (1,0), (1, 1), (1,2), (2,0), (2,1), (2,2)]             # batch_pot has the same dimension as batch.\n",
    "batch_subselection = [1 if el is not None else 0 for el in batch_plot]          # given the choice made before, we will only plot those files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intensity characterization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_dots         = fp.load_spots_distributed_files(dots_path, constants['SPOTS_FORMAT'])\n",
    "\n",
    "fig, axes = plt.subplots(lines, cols, figsize=(6, 6))\n",
    "for ind, file in enumerate(batch_fish):\n",
    "    if batch_subselection[ind]:\n",
    "        filebase_name = '_'.join(Path(file).stem.split('_')[:-1])\n",
    "        ind_l, ind_c  = batch_plot[ind]\n",
    "        ints          = dict_dots[filebase_name]['intensity'].to_numpy()\n",
    "        ints          = ints[~np.isnan(ints)]\n",
    " \n",
    "        pt.plot_intensities(ints, fig, axes, ind_l, ind_c,\n",
    "                                    leg_x[ind_c], leg_y[ind_l], name + '  Spot Intensity', color=color, color_mean= '#FF9D23', bins= 100, max_x = 4500) # modify the parameter max_x\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(Path(folder_path_figures)/f'{batch_name}_spots_intensity_{name}.png', bbox_inches=\"tight\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_dots         = fp.load_spots_distributed_files(dots_path, constants['SPOTS_FORMAT'])\n",
    "\n",
    "fig, axes = plt.subplots(lines, cols, figsize=(6, 6))\n",
    "for ind, file in enumerate(batch_fish):\n",
    "    if batch_subselection[ind]:\n",
    "        filebase_name = '_'.join(Path(file).stem.split('_')[:-1])\n",
    "        ind_l, ind_c  = batch_plot[ind]\n",
    "        \n",
    "        widths = dict_dots[filebase_name]['spot_width'].to_numpy()\n",
    "        widths = widths[~np.isnan(widths)]\n",
    "        \n",
    "        pt.plot_intensities(widths, fig, axes, ind_l, ind_c,\n",
    "                            leg_x[ind_c], leg_y[ind_l], name + '  Spot size', color=color, shape =(2,2), color_mean= '#FF9D23', bins= 30, max_x = 25, num_decimals=2)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(Path(folder_path_figures)/f'{batch_name}_spot_size_{name}.png', bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_dots = fp.load_spots_distributed_files(dots_path, constants['SPOTS_FORMAT'])\n",
    "\n",
    "fig, axes = plt.subplots(lines, cols, figsize=(6, 6))\n",
    "for ind, file in enumerate(batch_fish):\n",
    "    if batch_subselection[ind]:\n",
    "        ind_l, ind_c  = batch_plot[ind]\n",
    "        filebase_name = '_'.join(Path(file).stem.split('_')[:-1])\n",
    "\n",
    "        sum_i = dict_dots[filebase_name]['sum_intensity'].to_numpy()\n",
    "        sum_i = sum_i[~np.isnan(sum_i)]\n",
    "\n",
    "        pt.plot_intensities(sum_i, fig, axes, ind_l, ind_c,\n",
    "                            leg_x[ind_c], leg_y[ind_l], name + '  Summed spot intensity', color=color, shape =(2,2), color_mean= '#FF9D23', bins= 100, max_x = 500*500)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(Path(folder_path_figures)/  f'{batch_name}_mean_spot_intensities_{name}.png', bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visual QC\n",
    "\n",
    "dict_dots    = fp.load_spots_distributed_files(dots_path, constants['SPOTS_FORMAT'])\n",
    "\n",
    "viewer_spots = napari.Viewer(title=f\"Spot viewer {batch_name}\")\n",
    "counter      = 0\n",
    "for ind_l, file in enumerate(batch_fish):\n",
    "    if batch_subselection[ind_l]:\n",
    "        file_name     = '_'.join(Path(file).stem.split('_')[:-1])\n",
    "        ind_l, ind_c  = batch_plot[ind_l]\n",
    "    \n",
    "        im_rna    = io.imread(file)\n",
    "        if im_rna.ndim == 3:      \n",
    "            im_rna_2d = np.max(im_rna, axis=0)\n",
    "        elif im_rna.ndim == 2:\n",
    "            im_rna_2d = im_rna\n",
    "\n",
    "        val_max   = np.percentile(im_rna_2d, 99)\n",
    "        viewer_spots.add_image(im_rna_2d, contrast_limits=[0, val_max], rgb=False, name=f\"{file_name}\")\n",
    "       \n",
    "        df_spots  = dict_dots[file_name]\n",
    "                \n",
    "        filtered_df = df_spots[(df_spots['in_mask'] == True) & (df_spots['spot_width'].notna())]\n",
    "        if 'Z' in filtered_df.columns:\n",
    "            coords = filtered_df[['Z', 'Y', 'X']].to_numpy()[:,1:]\n",
    "        else:\n",
    "            coords = filtered_df[['Y', 'X']].to_numpy()\n",
    "                \n",
    "        temp_size = filtered_df['spot_width'].to_numpy()  \n",
    "          \n",
    "            \n",
    "        viewer_spots.add_points(coords, name=f\"Spots {file_name}\", size=temp_size.flatten(), border_color=color, face_color=[0, 0, 0, 0]);\n",
    "        \n",
    "        if counter !=0:\n",
    "            viewer_spots.layers[f\"{file_name}\"].visible       = False\n",
    "            viewer_spots.layers[f\"Spots {file_name}\"].visible = False    \n",
    "        counter = counter + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# snr  over experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "short_names = [f'NT 6h {chan_c}', f'NT 24h {chan_c}', f'NT 48h {chan_c}', f'GDF 6h {chan_c}', f'GDF 24h {chan_c}', f'GDF 48h {chan_c}',  f'FDF-GDF 6h {chan_c}', f'FDF-GDF 24h {chan_c}', f'FDF-GDF 48h {chan_c}' ]  # I define manually more concise names for the experiments        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_dots   = fp.load_spots_distributed_files(dots_path, constants['SPOTS_FORMAT'])\n",
    "\n",
    "ints, names = [], [] # format for plotting\n",
    "for ind, file in enumerate(batch_fish):\n",
    "    if batch_subselection[ind]:\n",
    "        file_name  = '_'.join(Path(file).stem.split('_')[:-1])\n",
    "        df_spots   = dict_dots[file_name] \n",
    "        intensities= df_spots[(df_spots['in_mask'] == True) & (df_spots['intensity'].notna())]['intensity'].to_numpy()\n",
    "        ints.append(intensities)\n",
    "        names.append(file_name)\n",
    " \n",
    "f_vp = pt.violin_plot_intensities(ints, figsize=(14,3), exp_name= 'Spot intensities' + f'{modality}_{chan_c}_{method}', rotation=85, names_short=short_names, color=color, ymax = 1500) #12500\n",
    "f_vp.savefig(Path(folder_path_figures)/f'{batch_name}_dots_int_{name}.png', bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_dots      = fp.load_spots_distributed_files(dots_path, constants['SPOTS_FORMAT'])\n",
    "\n",
    "snr_s          = []\n",
    "std_snr        = []\n",
    "bckgrd         = []\n",
    "bckgrd_std     = [] \n",
    "names          = []\n",
    "    \n",
    "snrs, bcks, names = [], [], [] # format for plotting\n",
    "     \n",
    "for ind, file in enumerate(batch_fish):\n",
    "    if batch_subselection[ind]:\n",
    "        file_name  = '_'.join(Path(file).stem.split('_')[:-1])\n",
    "        df_spots   = dict_dots[file_name] \n",
    "        snr        = df_spots[(df_spots['in_mask'] == True) & (df_spots['snr'].notna())]['snr'].to_numpy()\n",
    "        snrs.append(snr)\n",
    "        bck        = df_spots[(df_spots['in_mask'] == True) & (df_spots['background'].notna())]['background'].to_numpy()\n",
    "        bcks.append(bck)\n",
    "        names.append(file_name)\n",
    " \n",
    "f_snr = pt.violin_plot_intensities(snrs, figsize=(14,3), exp_name='SNRs ' + f'{modality}_{chan_c}_{method}', rotation=85, names_short=short_names, color=color, ymin= -0.3,ymax = 50)\n",
    "f_snr.savefig(Path(folder_path_figures)/f'{batch_name}_snr_{name}.png', bbox_inches=\"tight\")\n",
    "\n",
    "f_bck = pt.violin_plot_intensities(bcks, figsize=(14,3), exp_name='Background ' + f'{modality}_{chan_c}_{method}', rotation=85, names_short=short_names, color=color, ymax = 200)\n",
    "f_bck.savefig(Path(folder_path_figures)/f'{batch_name}_background_{name}.png', bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "WINDOW_SIZE        = window_size\n",
    "N_INT_POINTS       = n_int_points\n",
    "FRAC               = frac\n",
    "MEDIAN_FILT_SIZE   = median_filt_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "constants2 = tk.collect_constants()\n",
    "tk.save_constants_and_commit_hash(constants2, batch_name, folder_path = Path(f\"../Analysis/{batch_name}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base_env_apifish",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
