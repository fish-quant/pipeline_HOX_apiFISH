{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running the spot detection notebook, run the first notebook, \"HOX_Spot_detection_part_1.ipynb'.\n",
    "\n",
    "In this notebook we will detect the fish spots using a semi automatic method called BIGFISH.\n",
    "\n",
    "WARNING:  run this notebook in the usual environment 'base_env_apifish'.\n",
    "\n",
    "\n",
    "23/05/25     Jacques Bourg @ Florian Muller lab. Institut Pasteur.\n",
    "\n",
    "<img src=\"./HOX_pipeline.png\" alt=\"HOX pipeline\" width=\"1200\" height=\"477\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import skimage.io as io\n",
    "import napari\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "base_dir = Path(\"../../src\").resolve()\n",
    "sys.path.append(str(base_dir))\n",
    "sys.path.append(str(base_dir / \"utils\"))\n",
    "sys.path.append(str(base_dir / \"detection_fish\"))\n",
    "sys.path.append(str(base_dir / \"segmentation\"))\n",
    "\n",
    "from utils.parameters_tracking import Parameter_tracking as Track\n",
    "from utils.file_handling import FileProcessor\n",
    "from detection_fish.detect_fish_spots import DetectionPipeline\n",
    "from detection_fish.thresh_big_fish_napariV3 import SpotsThresholding \n",
    "from segmentation.refine_seg import Segmentation\n",
    "\n",
    "tk  = Track()\n",
    "det = DetectionPipeline()\n",
    "sg  = Segmentation()\n",
    "fp  = FileProcessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = str(Path('../Analysis'))\n",
    "batch_folders = os.listdir(var)\n",
    "dropdown = widgets.Dropdown(options=batch_folders, description='Select:', layout=widgets.Layout(width='auto', min_width='150px'))\n",
    "display(dropdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n         = np.where(np.array(batch_folders) == dropdown.value)[0][0]\n",
    "file_path = str(Path(var) / Path(batch_folders[n]) / Path(batch_folders[n] +'.json'))\n",
    "constants = tk.load_json(file_path)\n",
    "batch_name= constants['BATCH_NAME']; print(batch_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modalities = constants['MODALITIES']\n",
    "dropdown2 = widgets.Dropdown(options=modalities, description='Select:', layout=widgets.Layout(width='auto', min_width='150px'))\n",
    "display(dropdown2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n2       = np.where(np.array(modalities) == dropdown2.value)[0][0]\n",
    "modality = modalities[n2]; print(modality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_cell = constants['CHANNELS'] # (Doesn't make sense to select DAPI)\n",
    "dropdown3    = widgets.Dropdown(options=channel_cell, description='Select:', layout=widgets.Layout(width='auto', min_width='150px')); display(dropdown3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n3     = np.where(np.array(channel_cell) == dropdown3.value)[0][0]\n",
    "chan_c = channel_cell[n3]; print(chan_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_fish = constants[f'BATCH_{modality}_{chan_c}']; print(batch_fish);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spots_folder = Path(f'../Analysis/{batch_name}/{modality}/{chan_c}/spots')\n",
    "if not spots_folder.exists():\n",
    "    spots_folder.mkdir(parents=True)\n",
    "print(spots_folder)\n",
    "\n",
    "spots_bigfish_folder = Path(f'../Analysis/{batch_name}/{modality}/{chan_c}/spots/BIGFISH')\n",
    "if not spots_bigfish_folder.exists():\n",
    "    spots_bigfish_folder.mkdir(parents=True)\n",
    "print(spots_bigfish_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adjust the threshold by eye. Often there is some kind of inflexion point in the counts vs threshold curve at which the noise\n",
    " distribution and the signal distribution overlap.\n",
    "When one doesn't see this point look for a point in the noisy regime (left) which the derivative decreases in absolute value.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dots_ufish_path     = constants[f'DOTS_UFISH_{modality}_{chan_c}_PATH']\n",
    "format_spots        = constants[\"SPOTS_FORMAT\"]\n",
    "\n",
    "dict_ufish_dots     = fp.load_spots_distributed_files(dots_ufish_path, format=format_spots)\n",
    "dict_ufish_dots_raw = {key + '_' + chan_c: (val[['Z','Y','X']].to_numpy() if 'Z' in val.columns else val[['Y','X']].to_numpy())\n",
    " for key, val in dict_ufish_dots.items()}\n",
    "\n",
    "voxel_size_nm       = (108, 108)   # (z,y,x) or (y,x)  this parameter is important, you can check it's value opening the original files in fiji (Image/show info), or in the microscope metadata\n",
    "object_radius_nm    = (432, 432)   # estimate this parameter by eye: number of pixels of spots diameter times the voxels size (respective Z, Y and X dimension)\n",
    "im_dim              =  2           # change if needed  \n",
    "\n",
    "batch_path          = [Path(el) for el in batch_fish]\n",
    "dots_bigfish_path   = spots_bigfish_folder / f\"dots_{modality}_{chan_c}_BIGFISH.npy\"\n",
    "thresh_bigfish_path = spots_bigfish_folder / f\"thresh_{modality}_{chan_c}_BIGFISH.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sth0 = SpotsThresholding(BATCH = batch_path, BATCH_NAME= batch_name, voxel_size_nm=voxel_size_nm, \n",
    "                         object_radius_nm=object_radius_nm, spots_other_method=dict_ufish_dots_raw, subtract_fish=False)\n",
    "sth0.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After closing the app, pursue here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename the keys in order to have as key only the base name\n",
    "dict_dots = {}\n",
    "for key, value in sth0.detected_spots.items():\n",
    "    dict_dots['_'.join(key.split('_')[:-1])] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp.save_spots_distributed_files(dots_bigfish_path, format_spots, dict_dots, im_dim)\n",
    "np.save(thresh_bigfish_path, sth0.dict_thresh_spot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exec(f\"DOTS_BIGFISH_{modality}_{chan_c}_PATH = dots_bigfish_path\", globals())\n",
    "exec(f\"THRESH_BIGFISH_{modality}_{chan_c}_PATH = thresh_bigfish_path\", globals())\n",
    "\n",
    "exec(f\"VOXEL_SIZE_NM_BF_{modality}_{chan_c}_Z = voxel_size_nm[0]\", globals())\n",
    "exec(f\"VOXEL_SIZE_NM_BF_{modality}_{chan_c}_YX = voxel_size_nm[1]\", globals())\n",
    "exec(f\"OBJECT_RADIUS_NM_BF{modality}_{chan_c}_Z = object_radius_nm[0]\", globals())\n",
    "exec(f\"OBJECT_RADIUS_NM_BF{modality}_{chan_c}_YX = object_radius_nm[1]\", globals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "constants2 = tk.collect_constants()\n",
    "tk.save_constants_and_commit_hash(constants2, batch_name, folder_path = Path(f\"../Analysis/{batch_name}\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base_env_apifish",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
